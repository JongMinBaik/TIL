{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류: 참 대 허위, 양성 대 음성\n",
    "\n",
    "가정:\n",
    "    - \"늑대다\"는 *positive class*이다.\n",
    "    - \"늑대가 없다\"는 *negative class*이다.\n",
    "    \n",
    "### 1. 참양성(True Positive)\n",
    "- positive를 말했는데 그게 참이다.\n",
    "    - 현실: 늑대의 위협이 있음\n",
    "    - 양치기의 외침: \"늑대다\"\n",
    "    - 결과: 양치기는 영웅이 된다.\n",
    "    \n",
    "### 2. 허위 양성(Fasle Positive)\n",
    "- positive를 말했는데 그게 False다.\n",
    "    - 현실: 특대의 위협이 없음\n",
    "    - 양치기: \"늑대다\"\n",
    "    - 결과: 사람들 짜증\n",
    "    \n",
    "### 3. 허위 음성(False Negative)\n",
    "- negative를 말했는데 그게 False다.\n",
    "    - 현실: 늑대의 위협이 있음.\n",
    "    - 양치기: \"늑대가 없다\"\n",
    "    - 결과: ㅈ됨.\n",
    "    \n",
    "### 4. 참 음성(True Negative)\n",
    "- negative를 말했는데 그게 True임\n",
    "    - 현실: 늑대의 위협이 없음\n",
    "    - 양치기: \"늑대가 없다\"\n",
    "    - 결과: 아무일도 일어나지 않음.\n",
    "    \n",
    "\n",
    "# 정확성\n",
    "\n",
    "**정확성 = 정확한 예측수 / 총 예측수**\n",
    "\n",
    "이진 분류에서는\n",
    "정확성 = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "정확성이 좋아보인다고 좋은 모델은 아니다!\n",
    "- 정확성이 좋아도, 분류 능력이 떨어지는 모델은 정확성이 좋아보이는 것 뿐이다.\n",
    "\n",
    "e.g.\n",
    "총 100개의 데이터를 양성과 악성으로 분류할 때.\n",
    "TP: 1\n",
    "FP: 1\n",
    "FN: 8\n",
    "TN: 90\n",
    "이라면 정확성은 (1+90)/(1+90+1+8) = 0.91 이므로\n",
    "모델의 정확성은 91%가 된다.\n",
    "\n",
    "**하지만 Positive는 9개중 8개를 오진하므로 사실상 Positive에 대한 판별 능력이 없다.\n",
    "즉 Negative를 잘 판별하는 것인지, Positive의 판별능력이 떨어져서 Negative의 판별능력이 올라간 것처럼 보이는건지 알 수 없다.**\n",
    "\n",
    "ref: https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative?hl=ko\n",
    "\n",
    "  P  N      <- 실제 label\n",
    "P TP FP\n",
    "N FN TN\n",
    "\n",
    "^\n",
    "ㅣ\n",
    "TP+FN 은 항상 동일\n",
    "FP+TN 은 항상 동일\n",
    "\n",
    "판단된 label\n",
    "\n",
    "정밀도:\n",
    "    e.g. 양성으로 식별된 사례 중 실제로 양성이었던 사례의 비율은 어느 정도인가요?(모델의 결과를 가지고 판단)\n",
    "    - A class로 분류된 것 중 비율 x 정도 정확한게 들어있네(모여있네)\n",
    "    - 분류된 클래스 내에서 참의 비율\n",
    "    - 정밀도 = TP/(TP+FP)\n",
    "    \n",
    "재현율:\n",
    "    e.g. 실제 양성 중 정확히 양성이라고 식별된 사례의 비율은 어느 정도인가요?(모델의 성능을 가지고 판단)\n",
    "    - class를 얼마나 잘 분류했는가.\n",
    "    - 얼마나 옳게 분류했는지에 대한 비율\n",
    "    - 재현율 = TP/(TP+FN)\n",
    "    \n",
    "**정밀도 및 재현율은 줄다리기다.**\n",
    "    - 서로 상충할 때가 많다.\n",
    "    \n",
    "### ROC 곡선\n",
    "- ROC곡선은 모든 분류 임계값에서 분류 모델의 성능을 보여주는 그래프. 다음 두 매개변수를 표시한다.\n",
    "    1. 참 양성 비율(TPR) = TP/(TP+FN)\n",
    "    2. 허위 양성 비율(FPR) = FP/(FP+TN)\n",
    "    \n",
    "    - AUC: ROC 곡선 아래 영역\n",
    "    \n",
    "- AUC의 장점:\n",
    "    1. 척도 불변, AUC는 절대값이 아닌 예측이 얼마나 잘 평가되는지 측정\n",
    "    2. 분류 임계값 불변. 어떤 분류 임계값이 선택되었는지와 상관 없음\n",
    "    \n",
    "- AUC의 단점:\n",
    "    1. 척도 불변이 항상 이상적인 것은 아니다.\n",
    "    2. 분류 임계값 불변이 항상 이상적인 것은 아니다.\n",
    "    \n",
    "### EER(Equal Error Rate)\n",
    "\n",
    "- 동일 오류율: TPR == FPR이 같아지는 비율을 뜻한다.\n",
    "- 다른 ROC곡선을 가지는 장치의 정확도를 비교하기 위한 빠른 방법이다.\n",
    "- 일반적으로 가장 낮은 EER을 가지는 장치가 가장 정확하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAD",
   "language": "python",
   "name": "vad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
